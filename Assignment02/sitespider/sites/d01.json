{"id": "d01", "text": "\n\nGiven a character sequence and a defined document unit, \ntokenization is the task of chopping it up into pieces, called tokens, \nperhaps at the same time throwing away certain characters, \nsuch as punctuation. \n\n\n \n \n \n\n\n", "url": "http://people.f4.htw-berlin.de/~zhangg/pages/teaching/pages/d01.html", "back_links": ["d02", "d03", "d04"]}